{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_fine_tuning.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIaEUoQ_tbom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9jVy5qDN1nM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw69mj3GPMTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOOI5alZqObx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 乱数シードの固定\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "def reset_seed(seed=0):\n",
        "\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    session_conf = tf.ConfigProto(\n",
        "        intra_op_parallelism_threads=1,\n",
        "        inter_op_parallelism_threads=1\n",
        "    )\n",
        "\n",
        "    tf.set_random_seed(seed)\n",
        "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "    K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49PtIGIorICf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# モデルのインスタンス化\n",
        "reset_seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIkhEUsTx5rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "def expand2square(pil_img, background_color):\n",
        "    width, height = pil_img.size\n",
        "    if width == height:\n",
        "        return pil_img\n",
        "    elif width > height:\n",
        "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
        "        result.paste(pil_img, (0, (width - height) // 2))\n",
        "        return result\n",
        "    else:\n",
        "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
        "        result.paste(pil_img, ((height - width) // 2, 0))\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMNXRnemPocO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJaBbXZC5vHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "counter = 36\n",
        "for path in glob.glob('/content/gdrive/My Drive/PBL2/pbl_long_20191118/humei/**/*.png', recursive=True):\n",
        "    shutil.copy2(path, '/content/gdrive/My Drive/pbl_long_data/ok/'+str(counter).zfill(4)+'.png')\n",
        "    counter+=1\n",
        "    print(counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY7JQ2vyP1Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 分類するクラス\n",
        "classes = ['dakon', 'kizu', 'ok']\n",
        "nb_classes = len(classes)\n",
        "#画像の大きさを設定\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# トレーニング用とバリデーション用の画像格納先（パスは自分で設定してください）\n",
        "train_data_dir = '/content/gdrive/My Drive/pbl_long_data/'\n",
        "validation_data_dir = '/content/gdrive/My Drive/pbl_long_data/'\n",
        "for path in glob.glob(train_data_dir + '/**/*.png', recursive=True):\n",
        "    expand2square(Image.open(path), (0, 0, 0)).resize((224, 224)).save(path, quality=100)\n",
        "\n",
        "for path in glob.glob(validation_data_dir + '/**/*.png', recursive=True):\n",
        "    expand2square(Image.open(path), (0, 0, 0)).resize((224, 224)).save(path, quality=100)\n",
        "\n",
        "nb_train_samples =10  #トレーニングデータ用の画像数\n",
        "nb_validation_samples = 10  #バリデーション用の画像数\n",
        "batch_size = 100  #バッチサイズ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCMs6DNEVXKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# トレーンング用データを生成するジェネレータ作成\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale=1.0 / 255,\n",
        "#  zoom_range=0.2,\n",
        "  width_shift_range=0.1,\n",
        "  height_shift_range=0.1,\n",
        "  rotation_range=10,\n",
        "#  shear_range=0.1,\n",
        "  horizontal_flip=True,\n",
        "  vertical_flip=True,\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_data_dir,\n",
        "  target_size=(img_width, img_height),\n",
        "  color_mode='rgb',\n",
        "  classes=classes,\n",
        "  class_mode='categorical',\n",
        "  batch_size=batch_size,\n",
        "  shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLnAZOCbVYlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# バリデーション用データを生成するジェネレータ作成\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "  validation_data_dir,\n",
        "  target_size=(img_width, img_height),\n",
        "  color_mode='rgb',\n",
        "  classes=classes,\n",
        "  class_mode='categorical',\n",
        "  batch_size=batch_size,\n",
        "  shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq9R2aIZVzuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG16のロード。FC層は不要なので include_top=False\n",
        "input_tensor = Input(shape=(img_width, img_height, 3))\n",
        "vgg_conv = VGG16(weights='imagenet',\n",
        "                 include_top=False,\n",
        "                 input_tensor=input_tensor)\n",
        "\n",
        "# 終盤のConv層3つまでパラメータを固定\n",
        "for layer in vgg_conv.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# モデルの構築\n",
        "x = Flatten()(vgg_conv.layers[-1].output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(516, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(nb_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(vgg_conv.inputs, x)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = optimizers.Adam(lr=1e-4)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTLETOw49oIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/gdrive/My Drive/pbl_long_result/'\n",
        "\n",
        "modelcheckpoint = ModelCheckpoint(data_dir + 'best_model.hdf5', \n",
        "                                  monitor='val_loss', \n",
        "                                  verbose=0, \n",
        "                                  save_best_only=True, \n",
        "                                  save_weights_only=False, \n",
        "                                  mode='auto'\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzmSsEYGWtC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_epoch = 100000  #エポック数\n",
        "\n",
        "# Fine-tuning\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=nb_epoch,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks = [modelcheckpoint],\n",
        "#    samples_per_epoch=nb_train_samples,\n",
        "#    nb_val_samples=nb_validation_samples\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRAe2FiYE8Eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(data_dir + 'model.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFm1YtaZW1Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/gdrive/My Drive/pbl_long_result/'\n",
        "\n",
        "# 学習結果を描写\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "#acc, val_accのプロット\n",
        "plt.plot(history.history[\"acc\"], label=\"acc\", ls=\"-\", marker=\"o\")\n",
        "plt.plot(history.history[\"val_acc\"], label=\"val_acc\", ls=\"-\", marker=\"x\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend(loc=\"best\")\n",
        "#Final.pngという名前で、結果を保存\n",
        "plt.savefig(data_dir + 'model_acc.png')\n",
        "plt.show()\n",
        "\n",
        "#acc, val_accのプロット\n",
        "plt.plot(history.history[\"loss\"], label=\"loss\", ls=\"-\", marker=\"o\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\", ls=\"-\", marker=\"x\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend(loc=\"best\")\n",
        "#Final.pngという名前で、結果を保存\n",
        "plt.savefig(data_dir + 'model_loss.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pnSciff4mfw",
        "colab_type": "text"
      },
      "source": [
        "## Grad-CAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-vxOkZ33PZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITeczn734edB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Grad_Cam(input_model, x, layer_name):\n",
        "    '''\n",
        "    Args:\n",
        "       input_model: モデルオブジェクト\n",
        "       x: arary(正規化済み)\n",
        "       layer_name: 畳み込み層の名前\n",
        "\n",
        "    Returns:\n",
        "       jetcam: 影響の大きい箇所を色付けした画像(array)\n",
        "\n",
        "    '''\n",
        "\n",
        "    # 前処理\n",
        "    preprocessed_input = np.expand_dims(x, axis=0)\n",
        "    preprocessed_input = preprocessed_input.astype('float32')\n",
        "    preprocessed_input = preprocessed_input / 255.0\n",
        "\n",
        "    # 予測クラスの算出\n",
        "    predictions = input_model.predict(preprocessed_input)\n",
        "    class_idx = np.argmax(predictions[0])\n",
        "    class_output = input_model.output[:, class_idx]\n",
        "\n",
        "\n",
        "    #  勾配を取得\n",
        "\n",
        "    conv_output = input_model.get_layer(layer_name).output   # layer_nameのレイヤーのアウトプット\n",
        "    grads = K.gradients(class_output, conv_output)[0]  # gradients(loss, variables) で、variablesのlossに関しての勾配を返す\n",
        "    gradient_function = K.function([input_model.input], [conv_output, grads])  # model.inputを入力すると、conv_outputとgradsを出力する関数\n",
        "\n",
        "    output, grads_val = gradient_function([preprocessed_input])\n",
        "    output, grads_val = output[0], grads_val[0]\n",
        "\n",
        "    # 重みを平均化して、レイヤーのアウトプットに乗じる\n",
        "    weights = np.mean(grads_val, axis=(0, 1))\n",
        "    cam = np.dot(output, weights)\n",
        "\n",
        "\n",
        "    # 画像化してヒートマップにして合成\n",
        "\n",
        "    cam = cv2.resize(cam, (224, 224), cv2.INTER_LINEAR) # 画像サイズは200で処理したので\n",
        "    cam = np.maximum(cam, 0) \n",
        "    cam = cam / cam.max()\n",
        "\n",
        "    jetcam = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
        "    jetcam = cv2.cvtColor(jetcam, cv2.COLOR_BGR2RGB)  # 色をRGBに変換\n",
        "    jetcam = (np.float32(jetcam) + x / 2)   # もとの画像に合成\n",
        "\n",
        "    return jetcam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNwvW_AoHjdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/gdrive/My Drive/pbl_long_result/'\n",
        "for class_name in classes:\n",
        "    counter = 1\n",
        "    for path in glob.glob(validation_data_dir + class_name + '/**/*.png', recursive=True):\n",
        "        data = img_to_array(Image.open(path))\n",
        "        gradCAM_IMG = array_to_img(Grad_Cam(model, data, 'block5_conv3'))\n",
        "        org_IMG = array_to_img(data)\n",
        "        pred = classes[np.argmax(model.predict(data.reshape(1, data.shape[0], data.shape[1], data.shape[2])))]\n",
        "        gradCAM_IMG.save(data_dir + 'act_' + class_name + str(counter).zfill(4) + '_pred_' + pred + '_gradCAM.png', quality=100)\n",
        "        org_IMG.save(data_dir + 'act_' + class_name + str(counter).zfill(4) + '_pred_' + pred + '_org.png', quality=100)\n",
        "        counter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-vlaNLjK7vW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}